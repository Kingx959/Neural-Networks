{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 5676755,
          "sourceType": "datasetVersion",
          "datasetId": 3263390
        }
      ],
      "dockerImageVersionId": 30822,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "LipNet Model",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kingx959/Neural-Networks/blob/main/LipNet_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "mohamedbentalb_lipreading_dataset_path = kagglehub.dataset_download('mohamedbentalb/lipreading-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Mw5TEojFOBg0"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-03T17:24:03.569178Z",
          "iopub.execute_input": "2025-01-03T17:24:03.569558Z",
          "iopub.status.idle": "2025-01-03T17:24:10.918185Z",
          "shell.execute_reply.started": "2025-01-03T17:24:03.569529Z",
          "shell.execute_reply": "2025-01-03T17:24:10.916652Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "-Yj7ySi6OBg3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "from typing import List\n",
        "from matplotlib import pyplot as plt\n",
        "import imageio"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-03T17:24:14.619517Z",
          "iopub.execute_input": "2025-01-03T17:24:14.61989Z",
          "iopub.status.idle": "2025-01-03T17:24:26.053793Z",
          "shell.execute_reply.started": "2025-01-03T17:24:14.619863Z",
          "shell.execute_reply": "2025-01-03T17:24:26.052718Z"
        },
        "id": "6tPc_m2lOBg4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_device('GPU')"
      ],
      "metadata": {
        "trusted": true,
        "id": "Wg1DlS3pOBg4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "try:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "trusted": true,
        "id": "JGAF_nOWOBg4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_video(path:str) ->List[float]:\n",
        "\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
        "        ret, frame = cap.read()\n",
        "        frame = tf.image.rgb_to_grayscale(frame)\n",
        "        frames.append(frame[190:236,80:220,:])\n",
        "    cap.release()\n",
        "\n",
        "    mean = tf.math.reduce_mean(frames)\n",
        "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
        "    return tf.cast((frames - mean), tf.float32) / std"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-03T17:24:35.414276Z",
          "iopub.execute_input": "2025-01-03T17:24:35.414911Z",
          "iopub.status.idle": "2025-01-03T17:24:35.42192Z",
          "shell.execute_reply.started": "2025-01-03T17:24:35.41488Z",
          "shell.execute_reply": "2025-01-03T17:24:35.42058Z"
        },
        "id": "U1Hj94DoOBg5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-03T17:24:37.634207Z",
          "iopub.execute_input": "2025-01-03T17:24:37.634541Z",
          "iopub.status.idle": "2025-01-03T17:24:37.639405Z",
          "shell.execute_reply.started": "2025-01-03T17:24:37.634516Z",
          "shell.execute_reply": "2025-01-03T17:24:37.63823Z"
        },
        "id": "IkE72QEiOBg5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
        "num_to_char = tf.keras.layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
        "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-03T17:24:46.323733Z",
          "iopub.execute_input": "2025-01-03T17:24:46.324131Z",
          "iopub.status.idle": "2025-01-03T17:24:46.434052Z",
          "shell.execute_reply.started": "2025-01-03T17:24:46.324099Z",
          "shell.execute_reply": "2025-01-03T17:24:46.432762Z"
        },
        "id": "yPnrerD5OBg5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_alignments(path:str) -> List[str]:\n",
        "    with open(path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    tokens = []\n",
        "    for line in lines:\n",
        "        line = line.split()\n",
        "        if line[2] != 'sil':\n",
        "            tokens = [*tokens,' ',line[2]]\n",
        "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-03T17:24:52.807793Z",
          "iopub.execute_input": "2025-01-03T17:24:52.808282Z",
          "iopub.status.idle": "2025-01-03T17:24:52.815432Z",
          "shell.execute_reply.started": "2025-01-03T17:24:52.808238Z",
          "shell.execute_reply": "2025-01-03T17:24:52.813859Z"
        },
        "id": "ZBg71DOwOBg6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path: str):\n",
        "    path = bytes.decode(path.numpy())\n",
        "    file_name = path.split('/')[-1].split('.')[0]\n",
        "\n",
        "\n",
        "    video_path = os.path.join('/kaggle','input','lipreading-dataset','data','s1/',f'{file_name}.mpg')\n",
        "    alignment_path = os.path.join('/kaggle','input','lipreading-dataset','data','alignments','s1/',f'{file_name}.align')\n",
        "    frames = load_video(video_path)\n",
        "    alignments = load_alignments(alignment_path)\n",
        "\n",
        "    return frames, alignments"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-03T17:24:55.426333Z",
          "iopub.execute_input": "2025-01-03T17:24:55.426732Z",
          "iopub.status.idle": "2025-01-03T17:24:55.432611Z",
          "shell.execute_reply.started": "2025-01-03T17:24:55.4267Z",
          "shell.execute_reply": "2025-01-03T17:24:55.431325Z"
        },
        "id": "cRnLe3etOBg6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = '/kaggle/input/lipreading-dataset/data/s1/bbal6n.mpg'"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-03T17:24:57.867058Z",
          "iopub.execute_input": "2025-01-03T17:24:57.867394Z",
          "iopub.status.idle": "2025-01-03T17:24:57.872114Z",
          "shell.execute_reply.started": "2025-01-03T17:24:57.867369Z",
          "shell.execute_reply": "2025-01-03T17:24:57.870772Z"
        },
        "id": "uzUCTx2DOBg6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tf.convert_to_tensor(test_path).numpy().decode('utf-8').split('\\\\')[-1].split('.')[0]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-03T17:25:00.366601Z",
          "iopub.execute_input": "2025-01-03T17:25:00.367012Z",
          "iopub.status.idle": "2025-01-03T17:25:00.374969Z",
          "shell.execute_reply.started": "2025-01-03T17:25:00.366981Z",
          "shell.execute_reply": "2025-01-03T17:25:00.373764Z"
        },
        "id": "G0_4noyFOBg6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "frames, alignments = load_data(tf.convert_to_tensor(test_path))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-03T17:25:04.872107Z",
          "iopub.execute_input": "2025-01-03T17:25:04.872446Z",
          "iopub.status.idle": "2025-01-03T17:25:05.461802Z",
          "shell.execute_reply.started": "2025-01-03T17:25:04.87242Z",
          "shell.execute_reply": "2025-01-03T17:25:05.460396Z"
        },
        "id": "AFgtN4H9OBg6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join([bytes.decode(x) for x in num_to_char(alignments.numpy()).numpy()])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-03T17:25:11.166243Z",
          "iopub.execute_input": "2025-01-03T17:25:11.166749Z",
          "iopub.status.idle": "2025-01-03T17:25:11.177547Z",
          "shell.execute_reply.started": "2025-01-03T17:25:11.166621Z",
          "shell.execute_reply": "2025-01-03T17:25:11.176398Z"
        },
        "id": "bizePvAFOBg7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def mappable_function(path:str) ->List[str]:\n",
        "    result = tf.py_function(load_data, [path], (tf.float32, tf.int64))\n",
        "    return result"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-03T17:25:13.48061Z",
          "iopub.execute_input": "2025-01-03T17:25:13.481018Z",
          "iopub.status.idle": "2025-01-03T17:25:13.486165Z",
          "shell.execute_reply.started": "2025-01-03T17:25:13.480986Z",
          "shell.execute_reply": "2025-01-03T17:25:13.484763Z"
        },
        "id": "Fzl1Kb_lOBg7"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}